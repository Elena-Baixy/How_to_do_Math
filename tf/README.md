To get the attention map run
```
python test_gpt.py
```
To check what does each output mean, go to ```transformer/src/transformer/models/gpt2/modeling_gpt2.py``` and search ```TODO: print activation```, 
the output of the map will be in ```test_visualized_value```
